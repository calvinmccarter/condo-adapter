{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5b0a29-da38-4704-ac39-8fe0a8b66b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ot\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import condo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c53fdeb-c4ea-49e3-84cd-803dd7ddce04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IoffContext at 0x7fa4a587d3d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.rcParams[\"xtick.major.size\"] = 2\n",
    "plt.rcParams[\"ytick.major.size\"] = 2\n",
    "plt.rcParams['axes.linewidth'] = 0.5\n",
    "plt.rc('font', size=7) #controls default text size\n",
    "plt.rc('axes', titlesize=7) #fontsize of the title\n",
    "plt.rc('axes', labelsize=7) #fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=7) #fontsize of the x tick labels\n",
    "plt.rc('ytick', labelsize=7) #fontsize of the y tick labels\n",
    "plt.rc('legend', fontsize=7) #fontsize of the legend\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc4321fe-e8f5-42ae-b7a7-828d1038fe27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rix:0 NoiseFree-TargetShift-FeatureShift homoscedastic-linear\n",
      "epoch:0 -0.32743->-0.54934 avg:-0.50920\n",
      "rix:0 NoiseFree-TargetShift-FeatureShift heteroscedastic-linear\n",
      "epoch:0 -0.39955->-0.58319 avg:-0.54465\n",
      "rix:0 NoiseFree-TargetShift-FeatureShift nonlinear\n",
      "epoch:0 -0.76169->-0.66325 avg:-0.68650\n",
      "rix:0 NoiseFree-TargetShift-NoFeatureShift homoscedastic-linear\n",
      "epoch:0 -0.59589->-0.58343 avg:-0.58519\n",
      "rix:0 NoiseFree-TargetShift-NoFeatureShift heteroscedastic-linear\n",
      "epoch:0 -0.64868->-0.61931 avg:-0.62532\n",
      "rix:0 NoiseFree-TargetShift-NoFeatureShift nonlinear\n",
      "epoch:0 -0.79959->-0.77719 avg:-0.78756\n",
      "rix:0 NoiseFree-NoTargetShift-FeatureShift homoscedastic-linear\n",
      "epoch:0 -0.54266->-0.65573 avg:-0.63471\n",
      "rix:0 NoiseFree-NoTargetShift-FeatureShift heteroscedastic-linear\n",
      "epoch:0 -0.62109->-0.65310 avg:-0.64214\n",
      "rix:0 NoiseFree-NoTargetShift-FeatureShift nonlinear\n",
      "epoch:0 -0.65204->-0.66251 avg:-0.65521\n",
      "rix:0 NoiseFree-NoTargetShift-NoFeatureShift homoscedastic-linear\n",
      "epoch:0 -0.66287->-0.66670 avg:-0.66842\n",
      "rix:0 NoiseFree-NoTargetShift-NoFeatureShift heteroscedastic-linear\n",
      "epoch:0 -0.67856->-0.67723 avg:-0.67868\n",
      "rix:0 NoiseFree-NoTargetShift-NoFeatureShift nonlinear\n",
      "epoch:0 -0.71929->-0.72697 avg:-0.72522\n",
      "rix:0 Noisy-TargetShift-FeatureShift homoscedastic-linear\n",
      "epoch:0 -0.31462->-0.53562 avg:-0.49041\n",
      "rix:0 Noisy-TargetShift-FeatureShift heteroscedastic-linear\n",
      "epoch:0 -0.44566->-0.58141 avg:-0.55436\n",
      "rix:0 Noisy-TargetShift-FeatureShift nonlinear\n",
      "epoch:0 -0.74769->-0.66158 avg:-0.67911\n",
      "rix:0 Noisy-TargetShift-NoFeatureShift homoscedastic-linear\n",
      "epoch:0 -0.58701->-0.56769 avg:-0.57151\n",
      "rix:0 Noisy-TargetShift-NoFeatureShift heteroscedastic-linear\n",
      "epoch:0 -0.62138->-0.60457 avg:-0.60468\n",
      "rix:0 Noisy-TargetShift-NoFeatureShift nonlinear\n",
      "epoch:0 -0.80438->-0.76138 avg:-0.78013\n",
      "rix:0 Noisy-NoTargetShift-FeatureShift homoscedastic-linear\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    205\u001b[0m warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    206\u001b[0m cder \u001b[38;5;241m=\u001b[39m condo\u001b[38;5;241m.\u001b[39mConDoAdapter(\n\u001b[1;32m    207\u001b[0m     sampling\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproportional\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    208\u001b[0m     transform_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation-scale\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    212\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    213\u001b[0m )\n\u001b[0;32m--> 214\u001b[0m \u001b[43mcder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSbatch_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_S_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_T_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m Sreverse_ \u001b[38;5;241m=\u001b[39m cder\u001b[38;5;241m.\u001b[39mtransform(Sbatch_)\n\u001b[1;32m    216\u001b[0m Sreverse_test_ \u001b[38;5;241m=\u001b[39m cder\u001b[38;5;241m.\u001b[39mtransform(Sbatch_test_)\n",
      "File \u001b[0;32m~/sandbox/condo-adapter/condo/condo_adapter.py:1160\u001b[0m, in \u001b[0;36mConDoAdapter.fit\u001b[0;34m(self, S, T, X_S, X_T)\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation-scale\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1154\u001b[0m     \u001b[38;5;66;03m# location-scale transformation treats features independently\u001b[39;00m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_type \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1157\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhomoscedastic-gp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1158\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheteroscedastic-gp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1159\u001b[0m     )\n\u001b[0;32m-> 1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mM_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug_dict_ \u001b[38;5;241m=\u001b[39m \u001b[43mrun_kl_independent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mS\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_S\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_S\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_T\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_T\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdivergence\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdivergence\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_confounder_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_confounder_kernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptim_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/sandbox/condo-adapter/condo/condo_adapter.py:826\u001b[0m, in \u001b[0;36mrun_kl_independent\u001b[0;34m(S, T, X_S, X_T, Xtest, model_type, divergence, multi_confounder_kernel, debug, verbose, method, max_iter)\u001b[0m\n\u001b[1;32m    818\u001b[0m     (est_mu_S_all, est_sigma_S_all, predictor_S) \u001b[38;5;241m=\u001b[39m homoscedastic_gp_distr(\n\u001b[1;32m    819\u001b[0m         D\u001b[38;5;241m=\u001b[39mS,\n\u001b[1;32m    820\u001b[0m         X\u001b[38;5;241m=\u001b[39mX_S,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    823\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    824\u001b[0m     )\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheteroscedastic-gp\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 826\u001b[0m     (est_mu_T_all, est_sigma_T_all, predictor_T) \u001b[38;5;241m=\u001b[39m \u001b[43mheteroscedastic_gp_distr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mD\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_T\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mXtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mXtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_confounder_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_confounder_kernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m     (est_mu_S_all, est_sigma_S_all, predictor_S) \u001b[38;5;241m=\u001b[39m heteroscedastic_gp_distr(\n\u001b[1;32m    834\u001b[0m         D\u001b[38;5;241m=\u001b[39mS,\n\u001b[1;32m    835\u001b[0m         X\u001b[38;5;241m=\u001b[39mX_S,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    838\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    839\u001b[0m     )\n\u001b[1;32m    840\u001b[0m debug_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredictor_T\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m predictor_T\n",
      "File \u001b[0;32m~/sandbox/condo-adapter/condo/condo_adapter.py:587\u001b[0m, in \u001b[0;36mheteroscedastic_gp_distr\u001b[0;34m(D, X, Xtest, multi_confounder_kernel, verbose)\u001b[0m\n\u001b[1;32m    579\u001b[0m     alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100.0\u001b[39m\n\u001b[1;32m    580\u001b[0m     gper \u001b[38;5;241m=\u001b[39m GaussianProcessRegressor(\n\u001b[1;32m    581\u001b[0m         kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[1;32m    582\u001b[0m         alpha\u001b[38;5;241m=\u001b[39malpha,\n\u001b[1;32m    583\u001b[0m         normalize_y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    584\u001b[0m         n_restarts_optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m,\n\u001b[1;32m    585\u001b[0m     )\n\u001b[0;32m--> 587\u001b[0m \u001b[43mgper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# TODO: make faster when Xtest rows are not unique\u001b[39;00m\n\u001b[1;32m    590\u001b[0m (est_mu, est_sigma) \u001b[38;5;241m=\u001b[39m gper\u001b[38;5;241m.\u001b[39mpredict(Xtest, return_std\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:290\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_restarts_optimizer):\n\u001b[1;32m    288\u001b[0m         theta_initial \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng\u001b[38;5;241m.\u001b[39muniform(bounds[:, \u001b[38;5;241m0\u001b[39m], bounds[:, \u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    289\u001b[0m         optima\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 290\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constrained_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtheta_initial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m         )\n\u001b[1;32m    292\u001b[0m \u001b[38;5;66;03m# Select result from run with minimal (negative) log-marginal\u001b[39;00m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# likelihood\u001b[39;00m\n\u001b[1;32m    294\u001b[0m lml_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(itemgetter(\u001b[38;5;241m1\u001b[39m), optima))\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:603\u001b[0m, in \u001b[0;36mGaussianProcessRegressor._constrained_optimization\u001b[0;34m(self, obj_func, initial_theta, bounds)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constrained_optimization\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj_func, initial_theta, bounds):\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfmin_l_bfgs_b\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 603\u001b[0m         opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m            \u001b[49m\u001b[43minitial_theta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    610\u001b[0m         _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res)\n\u001b[1;32m    611\u001b[0m         theta_opt, func_min \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/scipy/optimize/_minimize.py:623\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[1;32m    621\u001b[0m                               \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[1;32m    627\u001b[0m                          \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/scipy/optimize/lbfgsb.py:360\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    354\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    356\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[0;32m--> 360\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:267\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[0;32m--> 267\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:233\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[0;32m--> 233\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/scipy/optimize/_differentiable_functions.py:134\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/scipy/optimize/optimize.py:74\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124;03m\"\"\" returns the the function value \"\"\"\u001b[39;00m\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/scipy/optimize/optimize.py:68\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 68\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:262\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.fit.<locals>.obj_func\u001b[0;34m(theta, eval_gradient)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobj_func\u001b[39m(theta, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 262\u001b[0m         lml, grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_marginal_likelihood\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclone_kernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    264\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mlml, \u001b[38;5;241m-\u001b[39mgrad\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:527\u001b[0m, in \u001b[0;36mGaussianProcessRegressor.log_marginal_likelihood\u001b[0;34m(self, theta, eval_gradient, clone_kernel)\u001b[0m\n\u001b[1;32m    524\u001b[0m     kernel\u001b[38;5;241m.\u001b[39mtheta \u001b[38;5;241m=\u001b[39m theta\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[0;32m--> 527\u001b[0m     K, K_gradient \u001b[38;5;241m=\u001b[39m \u001b[43mkernel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    529\u001b[0m     K \u001b[38;5;241m=\u001b[39m kernel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train_)\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:843\u001b[0m, in \u001b[0;36mSum.__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_gradient:\n\u001b[1;32m    842\u001b[0m     K1, K1_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk1(X, Y, eval_gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 843\u001b[0m     K2, K2_gradient \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mk2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_gradient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m K1 \u001b[38;5;241m+\u001b[39m K2, np\u001b[38;5;241m.\u001b[39mdstack((K1_gradient, K2_gradient))\n\u001b[1;32m    845\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/sandbox/condo-adapter/condo/heteroscedastic_kernel.py:104\u001b[0m, in \u001b[0;36mHeteroscedasticKernel.__call__\u001b[0;34m(self, X, Y, eval_gradient)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_prototypes):\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(K\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    102\u001b[0m         K_gradient[j, j, i] \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    103\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_2[i] \u001b[38;5;241m*\u001b[39m K_pairwise[i, j] \\\n\u001b[0;32m--> 104\u001b[0m             \u001b[38;5;241m/\u001b[39m \u001b[43mK_pairwise\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhyperparameter_gamma\u001b[38;5;241m.\u001b[39mfixed:\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;66;03m# XXX: Analytic expression for gradient?\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf\u001b[39m(gamma):  \u001b[38;5;66;03m# helper function\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/condo/lib/python3.8/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sum\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[38;5;241m=\u001b[39m_NoValue, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_sum\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_T = 200\n",
    "N_S = 100\n",
    "\n",
    "# How batch effect affects S\n",
    "batch_m = 2\n",
    "batch_b = 5\n",
    "\n",
    "# The true batch correction from Sbatch to S\n",
    "true_m = 1. / batch_m\n",
    "true_b = -1 * batch_b / batch_m\n",
    "\n",
    "noise_settings = [\"NoiseFree\", \"Noisy\",]\n",
    "targetshift_settings = [\"TargetShift\", \"NoTargetShift\",]\n",
    "featureshift_settings = [\"FeatureShift\", \"NoFeatureShift\"]\n",
    "\n",
    "prob_settings = [\"homoscedastic-linear\", \"heteroscedastic-linear\", \"nonlinear\"]\n",
    "#prob_settings = [\"nonlinear\"]\n",
    "num_probs = len(prob_settings)\n",
    "\n",
    "rMSEs = defaultdict(list)\n",
    "rMSEs_test = defaultdict(list)\n",
    "num_random = 5\n",
    "for rix in range(num_random):\n",
    "    rng = np.random.RandomState(rix)\n",
    "    for setting_combo in product(noise_settings, targetshift_settings, featureshift_settings):\n",
    "        (noise_setting, targetshift_setting, featureshift_setting) = setting_combo\n",
    "        setting_str = \"-\".join(setting_combo)\n",
    "        assert noise_setting in (\"Noisy\", \"NoiseFree\")\n",
    "        assert targetshift_setting in (\"NoTargetShift\", \"TargetShift\")\n",
    "        assert featureshift_setting in (\"NoFeatureShift\", \"FeatureShift\")\n",
    "\n",
    "        fig, axes = plt.subplots(\n",
    "            nrows=4, ncols=num_probs, sharex=\"all\", sharey=\"all\", squeeze=False,\n",
    "            gridspec_kw={\"hspace\": 0.03, \"wspace\": 0.03},\n",
    "            figsize=(6, 8), dpi=150)\n",
    "        msize = 1\n",
    "        basic_leg = ['target', 'source: true (unobserved)', 'source: batch-effected']\n",
    "        figname = f\"figure-continuous1d-{setting_str}-{rix}.pdf\"\n",
    "        fsizemse = 7\n",
    "\n",
    "        for pix, prob_setting in enumerate(prob_settings):\n",
    "            print(f\"rix:{rix} {setting_str} {prob_setting}\")\n",
    "            # Distribution of confounders\n",
    "            X_T = np.sort(np.random.uniform(0, 8, size=(N_T,)))\n",
    "            if targetshift_setting == \"TargetShift\":\n",
    "                X_S = np.sort(rng.uniform(4, 8, size=(N_S,)))\n",
    "                X_S_test = np.sort(rng.uniform(0, 8, size=(N_S,)))\n",
    "            elif targetshift_setting == \"NoTargetShift\":\n",
    "                X_S = np.sort(rng.uniform(0, 8, size=(N_S,)))\n",
    "                X_S_test = np.sort(rng.uniform(0, 8, size=(N_S,)))\n",
    "\n",
    "            if prob_setting == \"homoscedastic-linear\":\n",
    "                # How confounder X affects the distribution of T and S\n",
    "                theta_m = 4\n",
    "                theta_b = 1\n",
    "                phi_m = 0\n",
    "                phi_b = 2\n",
    "                mu_T = theta_m * X_T + theta_b\n",
    "                mu_S = theta_m * X_S + theta_b\n",
    "                mu_S_test = theta_m * X_S_test + theta_b\n",
    "                sigma_T = phi_m * X_T + phi_b\n",
    "                sigma_S = phi_m * X_S + phi_b\n",
    "                sigma_S_test = phi_m * X_S_test + phi_b\n",
    "                T = rng.normal(mu_T, sigma_T)\n",
    "                Strue = rng.normal(mu_S, sigma_S)\n",
    "                Strue_test = rng.normal(mu_S_test, sigma_S_test)\n",
    "            elif prob_setting == \"heteroscedastic-linear\":\n",
    "                # How confounder X affects the distribution of T and S\n",
    "                theta_m = 4\n",
    "                theta_b = 1\n",
    "                phi_m = 1\n",
    "                phi_b = 1\n",
    "                mu_T = theta_m * X_T + theta_b\n",
    "                mu_S = theta_m * X_S + theta_b\n",
    "                mu_S_test = theta_m * X_S_test + theta_b\n",
    "                sigma_T = phi_m * X_T + phi_b\n",
    "                sigma_S = phi_m * X_S + phi_b\n",
    "                sigma_S_test = phi_m * X_S_test + phi_b\n",
    "                T = rng.normal(mu_T, sigma_T)\n",
    "                Strue = rng.normal(mu_S, sigma_S)\n",
    "                Strue_test = rng.normal(mu_S_test, sigma_S_test)\n",
    "            elif prob_setting == \"nonlinear\":\n",
    "                # How confounder X affects the distribution of T and S\n",
    "                theta_m = 4\n",
    "                theta_b = 1\n",
    "                phi_m = 1\n",
    "                phi_b = 1\n",
    "                mu_T = theta_m * (np.maximum(X_T-5, 0) ** 2) + theta_b\n",
    "                mu_S = theta_m * (np.maximum(X_S-5, 0) ** 2) + theta_b\n",
    "                mu_S_test = theta_m * (np.maximum(X_S_test-5, 0) ** 2) + theta_b\n",
    "                sigma_T = phi_m * (np.maximum(X_T-5, 0) ** 2) + phi_b\n",
    "                sigma_S = phi_m * (np.maximum(X_S-5, 0) ** 2) + phi_b\n",
    "                sigma_S_test = phi_m * (np.maximum(X_S_test-5, 0) ** 2) + phi_b\n",
    "                T = rng.normal(mu_T, sigma_T)\n",
    "                Strue = rng.normal(mu_S, sigma_S)\n",
    "                Strue_test = rng.normal(mu_S_test, sigma_S_test)\n",
    "            if featureshift_setting == \"FeatureShift\":\n",
    "                Sbatch = batch_m * Strue + batch_b\n",
    "                Sbatch_test = batch_m * Strue_test + batch_b\n",
    "                oracle_m = true_m\n",
    "                oracle_b = true_b\n",
    "            elif featureshift_setting == \"NoFeatureShift\":\n",
    "                oracle_m = 1.0\n",
    "                oracle_b = 0.0\n",
    "                Sbatch = Strue.copy()\n",
    "                Sbatch_test = Strue_test.copy()\n",
    "\n",
    "            if noise_setting == \"NoiseFree\":\n",
    "                pass\n",
    "            elif noise_setting == \"Noisy\":\n",
    "                Sbatch = Sbatch + rng.normal(0, 1, size=(N_S,))\n",
    "                Sbatch_test = Sbatch_test + rng.normal(0, 1, size=(N_S,))\n",
    "\n",
    "            T_ = T.reshape(-1, 1) # (N_T, 1)\n",
    "            Strue_ = Strue.reshape(-1, 1) # (N_S, 1)\n",
    "            Sbatch_ = Sbatch.reshape(-1, 1)\n",
    "            X_T_ = X_T.reshape(-1, 1) # (N_T, 1)\n",
    "            X_S_ = X_S.reshape(-1, 1)\n",
    "            Strue_test_ = Strue_test.reshape(-1, 1) # (N_S, 1)\n",
    "            Sbatch_test_ = Sbatch_test.reshape(-1, 1)\n",
    "            X_S_test_ = X_S_test.reshape(-1, 1)\n",
    "            \n",
    "            # Before correction\n",
    "            method = \"before correction\"\n",
    "            axes[0, pix].tick_params(axis=\"both\", which=\"both\", direction=\"in\")    \n",
    "            axes[0, pix].scatter(X_T, T, s=msize)\n",
    "            axes[0, pix].scatter(X_S, Strue, s=msize)\n",
    "            axes[0, pix].scatter(X_S, Sbatch, s=msize)\n",
    "            rMSE = np.sqrt(np.mean((Sbatch - Strue) ** 2));\n",
    "            rMSEs[f\"{setting_str}_{prob_setting}_{method}\"].append(rMSE)\n",
    "            rMSE_test = np.sqrt(np.mean((Sbatch_test - Strue_test) ** 2));\n",
    "            rMSEs_test[f\"{setting_str}_{prob_setting}_{method}\"].append(rMSE_test)\n",
    "            avgrMSE = np.mean(rMSEs[f\"{setting_str}_{prob_setting}_{method}\"])\n",
    "            avgrMSE_test = np.mean(rMSEs_test[f\"{setting_str}_{prob_setting}_{method}\"])\n",
    "            axes[0, pix].text(\n",
    "                0.1, 0.9, f\"rMSE: {avgrMSE:.3f} ({avgrMSE_test:.3f})\", size=fsizemse,\n",
    "                transform = axes[0, pix].transAxes);\n",
    "            if pix == num_probs - 1:\n",
    "                axes[0, pix].legend(\n",
    "                    basic_leg,\n",
    "                    loc=\"center left\", bbox_to_anchor=(1.05, 0.5),\n",
    "                    frameon=False, borderpad=0.2, handlelength=0.3, borderaxespad=0.2);\n",
    "\n",
    "            # Oracle - not displayed\n",
    "            method = \"oracle-adapted\"\n",
    "            Soracle = oracle_m * Sbatch + oracle_b\n",
    "            Soracle_test = oracle_m * Sbatch_test + oracle_b\n",
    "            rMSE = np.sqrt(np.mean((Soracle - Strue) ** 2));\n",
    "            rMSEs[f\"{setting_str}_{prob_setting}_{method}\"].append(rMSE)\n",
    "            rMSE_test = np.sqrt(np.mean((Soracle_test - Strue_test) ** 2));\n",
    "            rMSEs_test[f\"{setting_str}_{prob_setting}_{method}\"].append(rMSE_test)\n",
    "            avgrMSE = np.mean(rMSEs[f\"{setting_str}_{prob_setting}_{method}\"])\n",
    "            avgrMSE_test = np.mean(rMSEs_test[f\"{setting_str}_{prob_setting}_{method}\"])\n",
    "\n",
    "            # OTDA\n",
    "            method = \"Gaussian OT\"\n",
    "            A_otda, b_otda = ot.da.OT_mapping_linear(Sbatch_, T_)\n",
    "            Sotda_ = Sbatch_.dot(A_otda) + b_otda\n",
    "            Sotda_test_ = Sbatch_test_.dot(A_otda) + b_otda\n",
    "            axes[1, pix].tick_params(axis=\"both\", which=\"both\", direction=\"in\")    \n",
    "            axes[1, pix].scatter(X_T, T, s=msize)\n",
    "            axes[1, pix].scatter(X_S, Strue, s=msize)\n",
    "            axes[1, pix].scatter(X_S, Sbatch, s=msize)\n",
    "            axes[1, pix].scatter(X_S, Sotda_, s=msize)\n",
    "            rMSE = np.sqrt(np.mean((Sotda_ - Strue_) ** 2));\n",
    "            rMSEs[f\"{setting_str}_{prob_setting}_{method}\"].append(rMSE)\n",
    "            rMSE_test = np.sqrt(np.mean((Sotda_test_ - Strue_test_) ** 2));\n",
    "            rMSEs_test[f\"{setting_str}_{prob_setting}_{method}\"].append(rMSE_test)\n",
    "            avgrMSE = np.mean(rMSEs[f\"{setting_str}_{prob_setting}_{method}\"])\n",
    "            avgrMSE_test = np.mean(rMSEs_test[f\"{setting_str}_{prob_setting}_{method}\"])\n",
    "            axes[1, pix].text(\n",
    "                0.1, 0.9, f\"rMSE: {avgrMSE:.3f} ({avgrMSE_test:.3f})\", size=fsizemse,\n",
    "                transform = axes[1, pix].transAxes);\n",
    "            if pix == num_probs - 1:\n",
    "                axes[1, pix].legend(\n",
    "                    basic_leg + [f\"source: {method}\"],\n",
    "                    loc=\"center left\", bbox_to_anchor=(1.05, 0.5),\n",
    "                    frameon=False, borderpad=0.2, handlelength=0.3, borderaxespad=0.2);\n",
    "\n",
    "            # ConDo using ReverseKL with linear Gaussian - not displayed\n",
    "            method = \"ConDo Linear-ReverseKL\"\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                cder = condo.ConDoAdapter(\n",
    "                    sampling=\"proportional\",\n",
    "                    transform_type=\"location-scale\",\n",
    "                    model_type=\"linear\",\n",
    "                    divergence=\"reverse\",\n",
    "                    debug=False,\n",
    "                    verbose=0\n",
    "                )\n",
    "                cder.fit(Sbatch_, T_, X_S_, X_T_)\n",
    "                Sreverse_ = cder.transform(Sbatch_)\n",
    "                Sreverse_test_ = cder.transform(Sbatch_test_)\n",
    "            rMSE = np.sqrt(np.mean((Sreverse_ - Strue_) ** 2));\n",
    "            rMSEs[f\"{setting_str}_{prob_setting}_{method}\"].append(rMSE)\n",
    "            rMSE_test = np.sqrt(np.mean((Sreverse_test_ - Strue_test_) ** 2));\n",
    "            rMSEs_test[f\"{setting_str}_{prob_setting}_{method}\"].append(rMSE_test)\n",
    "            avgrMSE = np.mean(rMSEs[f\"{setting_str}_{prob_setting}_{method}\"])\n",
    "            avgrMSE_test = np.mean(rMSEs_test[f\"{setting_str}_{prob_setting}_{method}\"])\n",
    "            \n",
    "            # ConDo using ReverseKL with heteroscedastic GP\n",
    "            method = \"ConDo GP-ReverseKL\"\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                cder = condo.ConDoAdapter(\n",
    "                    sampling=\"proportional\",\n",
    "                    transform_type=\"location-scale\",\n",
    "                    model_type=\"heteroscedastic-gp\",\n",
    "                    divergence=\"reverse\",\n",
    "                    debug=False,\n",
    "                    verbose=0\n",
    "                )\n",
    "                cder.fit(Sbatch_, T_, X_S_, X_T_)\n",
    "                Sreverse_ = cder.transform(Sbatch_)\n",
    "                Sreverse_test_ = cder.transform(Sbatch_test_)\n",
    "            rMSE = np.sqrt(np.mean((Sreverse_ - Strue_) ** 2));\n",
    "            rMSEs[f\"{setting_str}_{prob_setting}_{method}\"].append(rMSE)\n",
    "            rMSE_test = np.sqrt(np.mean((Sreverse_test_ - Strue_test_) ** 2));\n",
    "            rMSEs_test[f\"{setting_str}_{prob_setting}_{method}\"].append(rMSE_test)\n",
    "            avgrMSE = np.mean(rMSEs[f\"{setting_str}_{prob_setting}_{method}\"])\n",
    "            avgrMSE_test = np.mean(rMSEs_test[f\"{setting_str}_{prob_setting}_{method}\"])\n",
    "            axes[2, pix].tick_params(axis=\"both\", which=\"both\", direction=\"in\")    \n",
    "            axes[2, pix].scatter(X_T, T, s=msize)\n",
    "            axes[2, pix].scatter(X_S, Strue, s=msize)\n",
    "            axes[2, pix].scatter(X_S, Sbatch, s=msize)\n",
    "            axes[2, pix].scatter(X_S, Sreverse_, s=msize)\n",
    "            axes[2, pix].text(\n",
    "                0.1, 0.9, f\"rMSE: {avgrMSE:.3f} ({avgrMSE_test:.3f})\", size=fsizemse,\n",
    "                transform = axes[2, pix].transAxes);\n",
    "            if pix == num_probs - 1:\n",
    "                axes[2, pix].legend(\n",
    "                    basic_leg + [f\"source: {method}\"],\n",
    "                    loc=\"center left\", bbox_to_anchor=(1.05, 0.5),\n",
    "                    frameon=False, borderpad=0.2, handlelength=0.3, borderaxespad=0.2);\n",
    "\n",
    "            # Condo using MMD\n",
    "            method = \"ConDo MMD\"\n",
    "            with warnings.catch_warnings():\n",
    "                warnings.simplefilter(\"ignore\")\n",
    "                cder = condo.ConDoAdapter(\n",
    "                    sampling=\"proportional\",\n",
    "                    transform_type=\"location-scale\",\n",
    "                    model_type=\"empirical\",\n",
    "                    divergence=\"mmd\",\n",
    "                    optim_kwargs={\"epochs\": 25, \"alpha\": 0.01, \"beta\": 0.9},\n",
    "                    debug=False,\n",
    "                    verbose=1,\n",
    "                )\n",
    "                cder.fit(Sbatch_, T_, X_S_, X_T_)\n",
    "                Smmd_ = cder.transform(Sbatch_)\n",
    "                Smmd_test_ = cder.transform(Sbatch_test_)\n",
    "            rMSE = np.sqrt(np.mean((Smmd_ - Strue_) ** 2));\n",
    "            rMSEs[f\"{setting_str}_{prob_setting}_{method}\"].append(rMSE)\n",
    "            rMSE_test = np.sqrt(np.mean((Smmd_test_ - Strue_test_) ** 2));\n",
    "            rMSEs_test[f\"{setting_str}_{prob_setting}_{method}\"].append(rMSE_test)\n",
    "            avgrMSE = np.mean(rMSEs[f\"{setting_str}_{prob_setting}_{method}\"])\n",
    "            avgrMSE_test = np.mean(rMSEs_test[f\"{setting_str}_{prob_setting}_{method}\"])\n",
    "            axes[3, pix].tick_params(axis=\"both\", which=\"both\", direction=\"in\")    \n",
    "            axes[3, pix].scatter(X_T, T, s=msize)\n",
    "            axes[3, pix].scatter(X_S, Strue, s=msize)\n",
    "            axes[3, pix].scatter(X_S, Sbatch, s=msize)\n",
    "            axes[3, pix].scatter(X_S, Smmd_, s=msize)\n",
    "            axes[3, pix].text(\n",
    "                0.1, 0.9, f\"rMSE: {avgrMSE:.3f}  ({avgrMSE_test:.3f})\", size=fsizemse,\n",
    "                transform = axes[3, pix].transAxes);\n",
    "            if pix == num_probs - 1:\n",
    "                axes[3, pix].legend(\n",
    "                    basic_leg + [f\"source: {method}\"],\n",
    "                    loc=\"center left\", bbox_to_anchor=(1.05, 0.5),\n",
    "                    frameon=False, borderpad=0.2, handlelength=0.3, borderaxespad=0.2);\n",
    "        if rix in (0, num_random - 1):\n",
    "            fig.savefig(figname, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        with open(f\"rMSEs-after-{rix}.pickle\", \"wb\") as f:\n",
    "            pickle.dump(rMSEs, f)\n",
    "        with open(f\"rMSEs_test-after-{rix}.pickle\", \"wb\") as f:\n",
    "            pickle.dump(rMSEs_test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cea6709-cb26-4bc7-9517-e97639b53bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
